name: SLURM Integration Test

on:
  workflow_dispatch:
  pull_request:
    branches: [main]
    paths:
      - 'oellm/**'
      - 'tests/integration/**'
      - '.github/workflows/slurm-integration.yml'
      - 'apptainer/slurm-ci.def'

jobs:
  slurm-integration:
    name: SLURM + Apptainer Integration Test (GPU)
    runs-on: "runs-on=${{ github.run_id }}/family=g4dn.xlarge/image=ubuntu24-gpu-x64/volume=125g"
    timeout-minutes: 45

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Check GPU availability
        run: |
          echo "Checking for NVIDIA GPU..."
          nvidia-smi
          echo "GPU check passed"

      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y \
            software-properties-common \
            munge \
            slurm-wlm \
            slurm-wlm-basic-plugins \
            libmunge-dev

      - name: Install Apptainer
        run: |
          sudo add-apt-repository -y ppa:apptainer/ppa
          sudo apt-get update
          sudo apt-get install -y apptainer

      - name: Configure MUNGE
        run: |
          # Create munge key manually (create-munge-key not available on Ubuntu)
          sudo dd if=/dev/urandom of=/etc/munge/munge.key bs=1 count=1024
          sudo chown munge:munge /etc/munge/munge.key
          sudo chmod 400 /etc/munge/munge.key
          sudo systemctl start munge
          sudo systemctl status munge

      - name: Configure SLURM
        run: |
          HOSTNAME=$(hostname -s)

          sudo mkdir -p /etc/slurm
          sudo mkdir -p /var/spool/slurmd
          sudo mkdir -p /var/spool/slurmctld
          sudo mkdir -p /var/log/slurm

          # Create slurm.conf with GPU support
          sudo tee /etc/slurm/slurm.conf > /dev/null << EOF
          ClusterName=ci
          SlurmctldHost=${HOSTNAME}
          MpiDefault=none
          ProctrackType=proctrack/linuxproc
          ReturnToService=2
          SlurmctldPidFile=/var/run/slurmctld.pid
          SlurmdPidFile=/var/run/slurmd.pid
          SlurmdSpoolDir=/var/spool/slurmd
          SlurmUser=root
          StateSaveLocation=/var/spool/slurmctld
          SwitchType=switch/none
          TaskPlugin=task/none

          # Scheduling
          SchedulerType=sched/backfill
          SelectType=select/cons_tres
          SelectTypeParameters=CR_Core

          # Logging
          SlurmctldLogFile=/var/log/slurm/slurmctld.log
          SlurmdLogFile=/var/log/slurm/slurmd.log

          # GRES (GPU) configuration
          GresTypes=gpu

          # Node definition with GPU (use 15000 to account for system overhead on g4dn.xlarge)
          NodeName=${HOSTNAME} CPUs=4 Gres=gpu:1 RealMemory=15000 State=UNKNOWN
          PartitionName=gpu Nodes=${HOSTNAME} Default=YES MaxTime=INFINITE State=UP
          EOF

          # Create gres.conf for GPU
          sudo tee /etc/slurm/gres.conf > /dev/null << EOF
          NodeName=${HOSTNAME} Name=gpu File=/dev/nvidia0
          EOF

          # Set permissions
          sudo chmod 644 /etc/slurm/slurm.conf
          sudo chmod 644 /etc/slurm/gres.conf

      - name: Start SLURM services
        run: |
          sudo slurmctld -D &
          sleep 3
          sudo slurmd -D &
          sleep 3

          # Wait for node to be ready
          for i in {1..30}; do
            if sinfo | grep -q "idle"; then
              echo "SLURM node is ready"
              break
            fi
            echo "Waiting for SLURM node to become idle... ($i/30)"
            sleep 2
          done

          sinfo
          scontrol show node

      - name: Install uv
        uses: astral-sh/setup-uv@v7
        with:
          version: "latest"

      - name: Set up Python 3.12
        run: uv python install 3.12

      - name: Install oellm
        run: uv sync

      - name: Set up test environment
        env:
          EVAL_BASE_DIR: /tmp/oellm-test
          HF_HOME: /tmp/oellm-test/hf_data
          HF_DATASETS_CACHE: /tmp/oellm-test/hf_data/datasets
        run: |
          mkdir -p "$EVAL_BASE_DIR"
          mkdir -p "$HF_HOME/hub"
          mkdir -p "$HF_DATASETS_CACHE"
          mkdir -p "$EVAL_BASE_DIR/$USER"

      - name: Run integration test (full mode)
        env:
          EVAL_BASE_DIR: /tmp/oellm-test
        run: |
          uv run python tests/integration/test_slurm.py

      - name: Collect logs
        if: always()
        run: |
          mkdir -p /tmp/slurm-logs
          # SLURM daemon logs
          sudo cp -r /var/log/slurm/* /tmp/slurm-logs/ 2>/dev/null || true
          sudo chmod -R 755 /tmp/slurm-logs 2>/dev/null || true
          # Only copy the evaluation run directory (logs, scripts, results), not the container or cached data
          cp -r /tmp/oellm-test/runner /tmp/slurm-logs/ 2>/dev/null || true

      - name: Upload logs (on failure)
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: slurm-logs
          path: /tmp/slurm-logs/
          retention-days: 30

      - name: Upload logs (on success)
        if: success()
        uses: actions/upload-artifact@v4
        with:
          name: slurm-logs
          path: /tmp/slurm-logs/
          retention-days: 7
