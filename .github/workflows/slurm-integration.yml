name: SLURM Integration Test

on:
  workflow_dispatch:
  pull_request:
    branches: [main]
    paths:
      - 'oellm/**'
      - 'tests/integration/**'
      - '.github/workflows/slurm-integration.yml'

jobs:
  slurm-integration:
    name: SLURM + Apptainer Integration Test
    runs-on:
      - runs-on=${{ github.run_id }}
      - runner=gpu
      - family=g4dn
    timeout-minutes: 30

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Check GPU availability
        run: |
          echo "Checking for NVIDIA GPU..."
          nvidia-smi
          echo "GPU check passed"

      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y \
            software-properties-common \
            munge \
            slurm-wlm \
            slurm-wlm-basic-plugins \
            libmunge-dev

      - name: Install Apptainer
        run: |
          sudo add-apt-repository -y ppa:apptainer/ppa
          sudo apt-get update
          sudo apt-get install -y apptainer

      - name: Configure MUNGE
        run: |
          sudo create-munge-key --force
          sudo chown munge:munge /etc/munge/munge.key
          sudo chmod 400 /etc/munge/munge.key
          sudo systemctl start munge
          sudo systemctl status munge

      - name: Configure SLURM
        run: |
          HOSTNAME=$(hostname -s)

          sudo mkdir -p /etc/slurm
          sudo mkdir -p /var/spool/slurmd
          sudo mkdir -p /var/spool/slurmctld
          sudo mkdir -p /var/log/slurm

          # Create slurm.conf
          sudo tee /etc/slurm/slurm.conf > /dev/null << EOF
          ClusterName=ci
          SlurmctldHost=${HOSTNAME}
          MpiDefault=none
          ProctrackType=proctrack/linuxproc
          ReturnToService=2
          SlurmctldPidFile=/var/run/slurmctld.pid
          SlurmdPidFile=/var/run/slurmd.pid
          SlurmdSpoolDir=/var/spool/slurmd
          SlurmUser=root
          StateSaveLocation=/var/spool/slurmctld
          SwitchType=switch/none
          TaskPlugin=task/none

          # Scheduling
          SchedulerType=sched/backfill
          SelectType=select/cons_tres
          SelectTypeParameters=CR_Core

          # Logging
          SlurmctldLogFile=/var/log/slurm/slurmctld.log
          SlurmdLogFile=/var/log/slurm/slurmd.log

          # GRES (GPU) configuration
          GresTypes=gpu

          # Node definition
          NodeName=${HOSTNAME} CPUs=4 Gres=gpu:1 RealMemory=16000 State=UNKNOWN
          PartitionName=gpu Nodes=${HOSTNAME} Default=YES MaxTime=INFINITE State=UP
          EOF

          # Create gres.conf
          sudo tee /etc/slurm/gres.conf > /dev/null << EOF
          NodeName=${HOSTNAME} Name=gpu File=/dev/nvidia0
          EOF

          # Set permissions
          sudo chmod 644 /etc/slurm/slurm.conf
          sudo chmod 644 /etc/slurm/gres.conf

      - name: Start SLURM services
        run: |
          sudo slurmctld -D &
          sleep 3
          sudo slurmd -D &
          sleep 3

          # Wait for node to be ready
          for i in {1..30}; do
            if sinfo | grep -q "idle"; then
              echo "SLURM node is ready"
              break
            fi
            echo "Waiting for SLURM node to become idle... ($i/30)"
            sleep 2
          done

          sinfo
          scontrol show node

      - name: Install uv
        uses: astral-sh/setup-uv@v7
        with:
          version: "latest"

      - name: Set up Python 3.12
        run: uv python install 3.12

      - name: Install oellm
        run: uv sync

      - name: Build test container
        run: |
          apptainer build --fakeroot eval_env-ci.sif tests/integration/ci.def

      - name: Set up test environment
        env:
          EVAL_BASE_DIR: /tmp/oellm-test
          HF_HOME: /tmp/oellm-test/hf_data
          HF_DATASETS_CACHE: /tmp/oellm-test/hf_data/datasets
        run: |
          mkdir -p "$EVAL_BASE_DIR"
          mkdir -p "$HF_HOME/hub"
          mkdir -p "$HF_DATASETS_CACHE"
          mkdir -p "$EVAL_BASE_DIR/$USER"

          # Move container to expected location
          mv eval_env-ci.sif "$EVAL_BASE_DIR/"

          # Pre-download model and dataset
          uv run python << 'PYEOF'
          from huggingface_hub import snapshot_download
          from datasets import load_dataset
          import os

          hf_home = os.environ['HF_HOME']
          print(f'HF_HOME: {hf_home}')

          print('Downloading tiny-gpt2 model...')
          snapshot_download('sshleifer/tiny-gpt2', cache_dir=f'{hf_home}/hub')

          print('Downloading arc_easy dataset...')
          load_dataset('allenai/ai2_arc', 'ARC-Easy', trust_remote_code=True)

          print('Pre-download complete')
          PYEOF

      - name: Run integration test
        env:
          EVAL_BASE_DIR: /tmp/oellm-test
        run: |
          uv run python tests/integration/test_slurm.py

      - name: Upload logs on failure
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: slurm-logs
          path: |
            /var/log/slurm/
            /tmp/oellm-test/
